{"version":3,"sources":["App.js","reportWebVitals.js","index.js"],"names":["machine","initial","states","on","next","startWebcam","loadModel","identify","complete","showImage","showResults","App","useState","setResults","model","setModel","modelURL","setModelURL","webcam","setWebcam","objPred","setObjPred","modelReady","setModelReady","setShowResults","videoRef","useRef","useReducer","state","event","appState","dispatch","a","console","log","loadGraphModel","navigator","mediaDevices","getUserMedia","video","enumerateDevices","devices","webcamConfig","resizeWidth","resizeHeight","centerCrop","facingMode","tf","current","capture","img","offset","new_frame","sub","div","expandDims","reshape","execute","result","dataSync","predictions","Math","floor","actionButton","action","text","useEffect","timeout","setTimeout","clearTimeout","value","onChange","target","autoPlay","playsInline","muted","id","width","height","ref","onClick","reportWebVitals","onPerfEntry","Function","then","getCLS","getFID","getFCP","getLCP","getTTFB","ReactDOM","render","StrictMode","document","getElementById"],"mappings":"0XAKMA,G,OAAU,CACdC,QAAS,UACTC,OAAQ,CACND,QAAS,CAAEE,GAAI,CAAEC,KAAM,gBACvBC,YAAa,CAACF,GAAI,CAAEC,KAAM,cAC1BE,UAAW,CAAEH,GAAI,CAAEC,KAAM,aACzBG,SAAU,CAAEJ,GAAI,CAAEC,KAAM,aACxBI,SAAU,CAAEL,GAAI,CAAEC,KAAM,YAAcK,WAAW,EAAMC,aAAa,MAsIzDC,MA7Hf,WAAgB,IAAD,EACiBC,mBAAS,IAD1B,mBACGC,GADH,aAEaD,mBAAS,MAFtB,mBAENE,EAFM,KAECC,EAFD,OAGmBH,mBAAS,kDAH5B,mBAGNI,EAHM,KAGIC,EAHJ,OAIeL,mBAAS,MAJxB,mBAINM,EAJM,KAIEC,EAJF,OAKiBP,mBAAS,MAL1B,mBAKNQ,EALM,KAKGC,EALH,OAMuBT,oBAAS,GANhC,mBAMNU,EANM,KAMMC,EANN,OAOyBX,oBAAS,GAPlC,mBAONF,EAPM,KAOOc,EAPP,KAQPC,EAAWC,mBARJ,EAgBgBC,sBAFb,SAACC,EAAOC,GAAR,OACd7B,EAAQE,OAAO0B,GAAOzB,GAAG0B,IAAU7B,EAAQC,UACID,EAAQC,SAhB5C,mBAgBN6B,EAhBM,KAgBIC,EAhBJ,KAiBP3B,EAAO,kBAAM2B,EAAS,SAEtBzB,EAAS,uCAAG,4BAAA0B,EAAA,6DAChBC,QAAQC,IAAI,WAAalB,EAAW,OADpB,SAKImB,YAAenB,GALnB,OAKVF,EALU,OAOhBmB,QAAQC,IAAI,6BACZnB,EAASD,GACTS,GAAc,GACdnB,IAVgB,2CAAH,qDAcTC,EAAW,uCAAG,gCAAA2B,EAAA,4DACd,iBAAkBI,WAAa,iBAAkBA,UAAUC,cAC7DJ,QAAQC,IAAI,gCAEdE,UAAUC,aAAaC,aAAa,CAACC,OAAO,IAJ1B,SAMIH,UAAUC,aAAaG,mBAN3B,cAMZC,EANY,OAOlBR,QAAQC,IAAIO,GACNC,EAAe,CAAEC,YAAa,IAAKC,aAAc,IAAKC,YAAY,EAAOC,WAAY,eARzE,SASGC,IAAQ7B,OAAOO,EAASuB,QAAQN,GATnC,OASZxB,EATY,OAUlBC,EAAUD,GACLI,GACHhB,IAZgB,4CAAH,qDAgBXC,EAAQ,uCAAG,oCAAAyB,EAAA,sEACGd,EAAO+B,UADV,cACTC,EADS,OAEXC,EAASJ,IAAU,OACnBK,EAAYF,EAAIG,IAAIF,GACnBG,IAAIH,GACJI,aAAaC,QAAQ,EAAE,EAAG,IAAK,IAAK,IAL1B,SAMM1C,EAAM2C,QAAQL,GANpB,OAMTM,EANS,OAQfzB,QAAQC,IAAIwB,EAAOC,YACbC,EAAcF,EAAOC,WAC3BtC,EAAWwC,KAAKC,MAAqB,IAAfF,EAAY,KAClCpC,GAAe,GACfpB,IAZe,4CAAH,qDA0BR2D,EAAe,CACnB9D,QAAS,CAAE+D,OAAQ3D,EAAa4D,KAAM,SACtC5D,YAAa,CAAE4D,KAAM,sBACrB3D,UAAW,CAAE2D,KAAM,oBACnB1D,SAAU,CAAE0D,KAAM,kBAClBzD,SAAU,CAAEwD,OAhBH,uCAAG,sBAAAhC,EAAA,sDACZnB,EAAW,IACXT,IAFY,2CAAH,qDAgBkB6D,KAAM,UAmBnC,OAfAC,qBAAU,WACR,IAAMC,EAAUC,YAAW,WACrB9C,GAAcJ,GAChBX,MAED,KACH,OAAO,WACL8D,aAAaF,OAIjBD,qBAAU,WACR5D,MACC,CAACU,IAGF,gCACM,+BACA,yBAAQsD,MAAOtD,EAAUuD,SAjCZ,SAAC1C,GACpBN,GAAc,GACdN,EAAYY,EAAM2C,OAAOF,OACzBrC,QAAQC,IAAIL,EAAM2C,OAAOF,QA8BnB,UACE,wBAAQA,MAAM,iDAAd,kCACA,wBAAQA,MAAM,6CAAd,8BACA,wBAAQA,MAAM,+CAAd,gCACA,wBAAQA,MAAM,6CAAd,iCALF,cASJ,uBAAOG,UAAQ,EAACC,aAAW,EAACC,OAAK,EAACC,GAAG,SAASC,MAAM,MAAMC,OAAO,MAAMC,IAAKtD,IAC3Ef,GACC,8BAAMU,KAGNV,GACF,wBAAQsE,QAASjB,EAAajC,GAAUkC,QAAW,aAAnD,SACGD,EAAajC,GAAUmC,WC9HjBgB,EAZS,SAAAC,GAClBA,GAAeA,aAAuBC,UACxC,8BAAqBC,MAAK,YAAkD,IAA/CC,EAA8C,EAA9CA,OAAQC,EAAsC,EAAtCA,OAAQC,EAA8B,EAA9BA,OAAQC,EAAsB,EAAtBA,OAAQC,EAAc,EAAdA,QAC3DJ,EAAOH,GACPI,EAAOJ,GACPK,EAAOL,GACPM,EAAON,GACPO,EAAQP,OCDdQ,IAASC,OACP,cAAC,IAAMC,WAAP,UACE,cAAC,EAAD,MAEFC,SAASC,eAAe,SAM1Bb,M","file":"static/js/main.55361aa6.chunk.js","sourcesContent":["import React, { useState, useRef, useEffect, useReducer } from \"react\";\nimport * as tf from '@tensorflow/tfjs';\nimport {loadGraphModel} from '@tensorflow/tfjs-converter';\nimport \"./App.css\";\n\nconst machine = {\n  initial: \"initial\",\n  states: {\n    initial: { on: { next: \"startWebcam\" } },\n    startWebcam: {on: { next: \"loadModel\"}},\n    loadModel: { on: { next: \"identify\" } },\n    identify: { on: { next: \"complete\" }},\n    complete: { on: { next: \"identify\" }, showImage: true, showResults: true }\n  }\n};\n\n\n\n\n\n\nfunction App() {\n  const [results, setResults] = useState([]);\n  const [model, setModel] = useState(null);\n  const [modelURL, setModelURL] = useState('vww_128_color_bicycle_005_web_model/model.json');\n  const [webcam, setWebcam] = useState(null);\n  const [objPred, setObjPred] = useState(null);\n  const [modelReady, setModelReady] = useState(false);\n  const [showResults, setShowResults] = useState(false);\n  const videoRef = useRef();\n\n\n    //console.log(state);\n    //console.log(event);\n    //console.log(appState);\n  const reducer = (state, event) => \n    machine.states[state].on[event] || machine.initial;\n  const [appState, dispatch] = useReducer(reducer, machine.initial);\n  const next = () => dispatch(\"next\");\n\n  const loadModel = async () => {\n    console.log('Loading ' + modelURL + '...');\n  \n    // Load the model.\n    //const model = await tfjs-converter.loadGraphModel(MODEL_URL);\n    const model = await loadGraphModel(modelURL);\n    //net = await mobilenet.load();\n    console.log('Successfully loaded model');\n    setModel(model);\n    setModelReady(true);\n    next();\n\n  };\n\n  const startWebcam = async () => {\n    if ('mediaDevices' in navigator && 'getUserMedia' in navigator.mediaDevices) {\n      console.log(\"Let's get this party started\")\n    }\n    navigator.mediaDevices.getUserMedia({video: true})\n  \n    const devices = await navigator.mediaDevices.enumerateDevices();\n    console.log(devices);\n    const webcamConfig = { resizeWidth: 128, resizeHeight: 128, centerCrop: false, facingMode: 'environment'}\n    const webcam = await tf.data.webcam(videoRef.current,webcamConfig);\n    setWebcam(webcam);\n    if (!modelReady) {\n      loadModel();\n    }\n  };\n\n  const identify = async () => {\n    const img = await webcam.capture();\n    let offset = tf.scalar(127.5);\n    let new_frame = img.sub(offset)\n        .div(offset)\n        .expandDims().reshape([-1, 128, 128, 3]);\n    const result = await model.execute(new_frame);\n    //const results = await model.classify(imageRef.current);\n    console.log(result.dataSync());\n    const predictions = result.dataSync();\n    setObjPred(Math.floor(predictions[1]*100));\n    setShowResults(true);\n    next();\n  };\n\n  const reset = async () => {\n    setResults([]);\n    next();\n  };\n\n  const handleChange = (event) => {\n    setModelReady(false);\n    setModelURL(event.target.value);\n    console.log(event.target.value);\n  };\n\n  const actionButton = {\n    initial: { action: startWebcam, text: \"Start\" },\n    startWebcam: { text: \"Starting Webcam...\" },\n    loadModel: { text: \"Loading Model...\" },\n    identify: { text: \"Identifying...\" },\n    complete: { action: reset, text: \"Reset\" }\n  };\n\n \n  useEffect(() => {\n    const timeout = setTimeout(() => {\n      if (modelReady && webcam) {\n        identify();\n      }\n    }, 1000);\n    return () => {\n      clearTimeout(timeout);  // this guarantees to run right before the next effect\n    }\n  });\n\n  useEffect(() => {\n    loadModel();\n  }, [modelURL]); // Only re-run the effect if count changes\n  \n  return (\n    <div>\n          <h1>\n          <select value={modelURL} onChange={handleChange}>\n            <option value=\"vww_128_color_bicycle_005_web_model/model.json\">üö≤ Bicycle</option>\n            <option value=\"vww_128_color_dog_005_web_model/model.json\">üêï Dog</option>\n            <option value=\"vww_128_color_apple_005_web_model/model.json\">üçé Apple</option>\n            <option value=\"vww_128_color_car_005_web_model/model.json\">üöò Car</option>\n          </select>\n          Detector\n          </h1>\n      <video autoPlay playsInline muted id=\"webcam\" width=\"600\" height=\"600\" ref={videoRef} />\n      {showResults && (\n        <div>{objPred}</div>\n\n      )}\n      {!showResults && (\n      <button onClick={actionButton[appState].action || (() => {})}>\n        {actionButton[appState].text}\n      </button>\n      )}\n\n    </div>\n  );\n}\n\nexport default App;","const reportWebVitals = onPerfEntry => {\n  if (onPerfEntry && onPerfEntry instanceof Function) {\n    import('web-vitals').then(({ getCLS, getFID, getFCP, getLCP, getTTFB }) => {\n      getCLS(onPerfEntry);\n      getFID(onPerfEntry);\n      getFCP(onPerfEntry);\n      getLCP(onPerfEntry);\n      getTTFB(onPerfEntry);\n    });\n  }\n};\n\nexport default reportWebVitals;\n","import React from 'react';\nimport ReactDOM from 'react-dom';\nimport './index.css';\nimport App from './App';\nimport reportWebVitals from './reportWebVitals';\n\nReactDOM.render(\n  <React.StrictMode>\n    <App />\n  </React.StrictMode>,\n  document.getElementById('root')\n);\n\n// If you want to start measuring performance in your app, pass a function\n// to log results (for example: reportWebVitals(console.log))\n// or send to an analytics endpoint. Learn more: https://bit.ly/CRA-vitals\nreportWebVitals();\n"],"sourceRoot":""}